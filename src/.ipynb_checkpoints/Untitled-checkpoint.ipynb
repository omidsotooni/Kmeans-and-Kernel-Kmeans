{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d297ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import sys\n",
    "from LoadData import * \n",
    "from k_means import * \n",
    "from evaluation import * \n",
    "from kernel_k_means import * \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09de69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def squaredDistance(vec1, vec2):\n",
    "    sum = 0 \n",
    "    dim = len(vec1) \n",
    "    \n",
    "    for i in range(dim):\n",
    "        sum += (vec1[i] - vec2[i]) * (vec1[i] - vec2[i]) \n",
    "    \n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d1685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe5dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoadData\n",
    "def loadPoints(filename):\n",
    "    input = open(filename, \"r\")\n",
    "    \n",
    "    info = input.readline().split()\n",
    "    \n",
    "# number of data points and dimension\n",
    "    # already know: (1)# of data points (2)dimension --> first line of the data file\n",
    "    nData = int(info[0]) \n",
    "    nDim = int(info[1])\n",
    "    \n",
    "# create data matrix\n",
    "    data = [[0]*nDim for i in range(nData)]\n",
    "\n",
    "    for i in range(nData):\n",
    "        info = input.readline().split()\n",
    "        for j in range(nDim):\n",
    "            data[i][j] = float(info[j]) \n",
    "\n",
    "    return data \n",
    "\n",
    "def loadClusters(filename): \n",
    "    input = open(filename, \"r\") \n",
    "    \n",
    "    info = input.readline() \n",
    "    \n",
    "    nData = int(info)\n",
    "    \n",
    "    clusters = [0] * nData \n",
    "    \n",
    "    for i in range(nData):\n",
    "        info = input.readline()\n",
    "        clusters[i] = int(info)\n",
    "    \n",
    "    return clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea0407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028b4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "from math import log, sqrt\n",
    "\n",
    "def count_occurrence(list):\n",
    "    \"\"\"\n",
    "    count the occurrences of a list item\n",
    "    :param list:\n",
    "    :return: dictionary {element:occurrence}\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for i in list:\n",
    "        if i in d:\n",
    "            d[i] += 1\n",
    "        else:\n",
    "            d[i] = 1\n",
    "    return d\n",
    "\n",
    "def cal_entropy(assignment):\n",
    "    \"\"\"\n",
    "    calculate the entropy of clustering\n",
    "    :param assignment: the assignment for the data, list: [0,1,0,0, ....]\n",
    "    :return: entropy\n",
    "    \"\"\"\n",
    "    occ = count_occurrence(assignment) # get # of data points in each cluster, dictionary\n",
    "    n = float(sum(occ.values())) # number of data points\n",
    "    h = 0 # entropy of cluster\n",
    "    for id in occ:\n",
    "        p = occ[id] / n # the probability of cluster C_id\n",
    "        if p != 0:\n",
    "            h += p*log(p)\n",
    "    return -h\n",
    "\n",
    "def purity(groundtruthAssignment, algorithmAssignment):\n",
    "    purity = 0\n",
    "    # TODO  \n",
    "    # Compute the purity\n",
    "    ids = sorted(set(algorithmAssignment)) # sorted unique clusterID\n",
    "    matching = 0\n",
    "    for id in ids:\n",
    "        # get the index from clusterID where data points belong to the same cluster\n",
    "        indices = [i for i, j in enumerate(algorithmAssignment) if j == id]\n",
    "        cluster = [groundtruthAssignment[i] for i in indices]\n",
    "        occ = count_occurrence(cluster)\n",
    "        matching += max(occ.values())\n",
    "    purity =  matching / float(len(groundtruthAssignment))\n",
    "    return purity \n",
    "\n",
    "\n",
    "def NMI(groundtruthAssignment, algorithmAssignment):\n",
    "\n",
    "    NMI = 0\n",
    "    # TODO\n",
    "    # Compute the NMI\n",
    "    ## compute entropy\n",
    "    h_c = cal_entropy(algorithmAssignment) # Entropy of clustering C\n",
    "    h_t = cal_entropy(groundtruthAssignment) # Entropy of partitioning T\n",
    "\n",
    "    ## compute Mutual information\n",
    "    occ_c = count_occurrence(algorithmAssignment) # get occurrence: for the probability of cluster C_id\n",
    "    n_c = float(sum(occ_c.values())) # total # of cluster C_id\n",
    "    occ_t = count_occurrence(groundtruthAssignment) # get occurrence: for the probability of cluster T_id\n",
    "    n_t = float(sum(occ_t.values())) # total # of cluster T_id\n",
    "    ids_c = sorted(set(algorithmAssignment))\n",
    "    ids_t = sorted(set(groundtruthAssignment))\n",
    "\n",
    "    # cartesian product for all possible id combination\n",
    "    cp = [(i,j) for i in ids_c for j in ids_t]\n",
    "    # dictionary for the shared information, e.g.,{(0, 1): 0, (1, 0): 0, (0, 0): 0, (1, 1): 0}\n",
    "    p = dict(zip(cp,[0]*len(cp)))\n",
    "\n",
    "    for (i,j) in zip(algorithmAssignment,groundtruthAssignment):\n",
    "            p[(i,j)] += 1\n",
    "\n",
    "    mi = 0 # mutual information\n",
    "    for c in ids_c:\n",
    "        for t in ids_t:\n",
    "            if p[(c,t)] != 0:\n",
    "                mi += (p[(c,t)]/n_c) * log( (p[(c,t)]/n_c) / ((occ_c[c]/n_c)*(occ_t[t]/n_t)) )\n",
    "    NMI = mi / sqrt(float(h_c*h_t))\n",
    "    return NMI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54625aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca93122c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\OMIDSO~1\\AppData\\Local\\Temp/ipykernel_1448/320108218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mgroundtruthFilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mgroundtruth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadClusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroundtruthFilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Arshad(MS)\\Courses\\01 - Data Mining\\Programs\\Exercise\\Kmeans-and-Kernel-Kmeans\\src\\LoadData.py\u001b[0m in \u001b[0;36mloadPoints\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "# k_means\n",
    "import sys\n",
    "from LoadData import * \n",
    "from k_means import * \n",
    "from evaluation import * \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print (\"[usage] <data-file> <ground-truth-file>\")\n",
    "        exit(1) \n",
    "    \n",
    "    dataFilename = sys.argv[1]\n",
    "    groundtruthFilename = sys.argv[2]\n",
    "    \n",
    "    data = loadPoints(dataFilename) \n",
    "    groundtruth = loadClusters(groundtruthFilename) \n",
    "    \n",
    "    nDim = len(data[0]) \n",
    "   \n",
    "    K = 3  # Suppose there are 2 clusters\n",
    "    print ('K=',K)\n",
    "\n",
    "    # use the first two data points as initial cluster centers\n",
    "    centers = []\n",
    "    for i in range(K):\n",
    "        centers.append(data[i])\n",
    "\n",
    "\n",
    "    # get clusterID, list\n",
    "    results = kmeans(data, centers) \n",
    "\n",
    "    res_Purity = purity(groundtruth, results) \n",
    "    res_NMI = NMI(groundtruth, results) \n",
    "    \n",
    "    print (\"Purity =\", res_Purity)\n",
    "    print (\"NMI = \", res_NMI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368674d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f700f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_k_means\n",
    "from utils import * \n",
    "from math import exp \n",
    "\n",
    "def kernel(data, sigma):\n",
    "    \"\"\"\n",
    "    RBF kernel-k-means\n",
    "    :param data: data points: list of list [[a,b],[c,d]....]\n",
    "    :param sigma: Gaussian radial basis function\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nData = len(data)\n",
    "    Gram = [[0] * nData for i in range(nData)] # nData x nData matrix\n",
    "    # TODO\n",
    "    # Calculate the Gram matrix\n",
    "\n",
    "    # symmetric matrix\n",
    "    for i in range(nData):\n",
    "        for j in range(i,nData):\n",
    "            if i != j: # diagonal element of matrix = 0\n",
    "                # RBF kernel: K(xi,xj) = e ( (-|xi-xj|**2) / (2sigma**2)\n",
    "                square_dist = squaredDistance(data[i],data[j])\n",
    "                base = 2.0 * sigma**2\n",
    "                Gram[i][j] = exp(-square_dist/base)\n",
    "                Gram[j][i] = Gram[i][j]\n",
    "    return Gram \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e85668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0c9d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\OMIDSO~1\\AppData\\Local\\Temp/ipykernel_1448/2846995964.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mgroundtruthFilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mgroundtruth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadClusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroundtruthFilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Arshad(MS)\\Courses\\01 - Data Mining\\Programs\\Exercise\\Kmeans-and-Kernel-Kmeans\\src\\LoadData.py\u001b[0m in \u001b[0;36mloadPoints\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadPoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "# main_kernel_k_means\n",
    "import imp\n",
    "import sys\n",
    "from LoadData import * \n",
    "from k_means import * \n",
    "from evaluation import * \n",
    "from kernel_k_means import * \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print (\"[usage] <data-file> <ground-truth-file>\")\n",
    "        exit(1) \n",
    "    \n",
    "    dataFilename = sys.argv[1]\n",
    "    groundtruthFilename = sys.argv[2]\n",
    "    \n",
    "    data = loadPoints(dataFilename) \n",
    "    groundtruth = loadClusters(groundtruthFilename) \n",
    "\n",
    "    sigma = 4.0\n",
    "    \n",
    "    data = kernel(data, sigma)  \n",
    "\n",
    "    nDim = len(data[0]) \n",
    "   \n",
    "    K = 5  # Suppose there are 2 clusters\n",
    "    print ('K=',K)\n",
    "\n",
    "    centers = []\n",
    "    for i in range(K):\n",
    "        centers.append(data[i])\n",
    "    \n",
    "    results = kmeans(data, centers)\n",
    "\n",
    "    res_Purity = purity(results, groundtruth)\n",
    "    res_NMI = NMI(results, groundtruth) \n",
    "    \n",
    "    print (\"Purity =\", res_Purity)\n",
    "    print (\"NMI = \", res_NMI)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b062904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
